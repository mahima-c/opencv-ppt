{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operations With OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading an image using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 251]\n",
      "  [255 255 252]\n",
      "  [249 254 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [254 254 254]\n",
      "  [255 254 255]]\n",
      "\n",
      " [[255 255 252]\n",
      "  [254 255 253]\n",
      "  [246 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 254 255]]\n",
      "\n",
      " [[250 255 255]\n",
      "  [243 252 255]\n",
      "  [237 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 254 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "Image Properties\n",
      "- Number of Pixels: 251667\n",
      "- Shape/Dimensions: (239, 351, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img=cv2.imread('Picture1-1.jpg',1)#read a image \n",
    "print(img)\n",
    "cv2.imshow(\"display\",img)\n",
    "h=cv2.waitKey(0)#when you anykey its store in h,27 is for q\n",
    "if h==ord('q'):\n",
    "    cv2.destroyAllWindows()\n",
    "elif h== ord('s'):\n",
    "    cv2.imwrite('hcopy.png',img)\n",
    "    cv2.destroyAllWindows()\n",
    "print(\"Image Properties\")\n",
    "print(\"- Number of Pixels: \" + str(img.size))\n",
    "print(\"- Shape/Dimensions: \" + str(img.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239, 351, 3)\n",
      "251667\n",
      "uint8\n",
      "[[[ 60  45  13]\n",
      "  [ 66  47  14]\n",
      "  [ 62  40   4]\n",
      "  ...\n",
      "  [114  80  34]\n",
      "  [106  71  27]\n",
      "  [109  70  31]]\n",
      "\n",
      " [[ 83  63  28]\n",
      "  [ 84  60  24]\n",
      "  [ 84  58  21]\n",
      "  ...\n",
      "  [111  76  32]\n",
      "  [ 98  63  20]\n",
      "  [ 93  54  16]]\n",
      "\n",
      " [[ 46  22   0]\n",
      "  [ 54  28   0]\n",
      "  [ 78  52  12]\n",
      "  ...\n",
      "  [125  95  54]\n",
      "  [103  69  33]\n",
      "  [ 81  44  10]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[251 250 254]\n",
      "  [251 250 252]\n",
      "  [251 250 252]\n",
      "  ...\n",
      "  [253 251 251]\n",
      "  [253 251 251]\n",
      "  [253 251 251]]\n",
      "\n",
      " [[253 252 254]\n",
      "  [251 253 253]\n",
      "  [251 253 253]\n",
      "  ...\n",
      "  [255 252 254]\n",
      "  [255 252 254]\n",
      "  [255 252 254]]\n",
      "\n",
      " [[254 255 253]\n",
      "  [252 255 251]\n",
      "  [250 255 250]\n",
      "  ...\n",
      "  [254 254 254]\n",
      "  [255 254 254]\n",
      "  [254 254 254]]]\n"
     ]
    }
   ],
   "source": [
    "#perform some basic operation on images(arithematic operation)\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=cv2.imread('Picture1-1.jpg',1)\n",
    "# img2=cv2.imread('ex.jpg',1)\n",
    "cv2.imshow(\"img\",img)\n",
    "\n",
    "# print(img)\n",
    "# print()\n",
    "\n",
    "print(img.shape)# it return no of coloum and row  and channel in tuple formate\n",
    "print(img.size)#total no of pixel is accessed\n",
    "print(img.dtype)#return image data type is obtained\n",
    "\n",
    "b,g,r=cv2.split(img)\n",
    "cv2.imshow(\"blue\",b)\n",
    "cv2.imshow(\"green\",g)\n",
    "cv2.imshow(\"red\",r)\n",
    "\n",
    "image_RGB=cv2.merge((r,g,b))\n",
    "cv2.imshow(\"image_RGB\",image_RGB)\n",
    "\n",
    "region=img[200:250, 200:250]\n",
    "print(region)\n",
    "\n",
    "# img[100:150,100:150]=region\n",
    "# cv2.imshow(\"blueq\",img)\n",
    "\n",
    "# print(b)\n",
    "# print(g)\n",
    "# print(r)\n",
    "\n",
    "#ROI(REGION OF INTRESET)\n",
    "# img=cv2.resize(img,(512,512))\n",
    "# img2=cv2.resize(img2,(512,512))\n",
    "\n",
    "# dst=cv2.add(img,img2)\n",
    "# dst2=cv2.addWeighted(img,.9,img2,.1,0)\n",
    "# cv2.imshow('image',dst2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*239*351"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we create a VideoWriter object. We should specify the output file name (eg: output.avi). \n",
    "Then we should specify the FourCC code (details in next paragraph). Then number of frames per second (fps) and \n",
    "frame size should be passed. And last one is isColor flag. If it is True, encoder expect color frame, otherwise it \n",
    "works with grayscale frame.\n",
    "\n",
    "FourCC is a 4-byte code used to specify the video codec. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### capture livestream from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#if we want to read viedo from anyfile then give filename as parameter of viedocapture\n",
    "#for read from camera give the index 0 or some device have -1 also and if we have multiple camera then we use index as 1,2,3 as.\n",
    "cap= cv2.VideoCapture(0);\n",
    "#create class for write viedo      fourcc code which is specify for viedo codec ,identify the data formate\n",
    "# Define the codec and create VideoWriter object\n",
    "\n",
    "fourcc=cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi',fourcc,20.0,(640,480))\n",
    "while(True):\n",
    "    #for capture\n",
    "    ret,frame = cap.read()\n",
    "    #if frame is available then ret is ture otherwise false\n",
    "\n",
    "    if ret ==True:\n",
    "        \n",
    "        #PROP ID are many to know the property\n",
    "#         print(\"width:\",cap.get(cv2.CAP_PROP_FRAME_WIDTH),\"height:\",cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        \n",
    "        # write the flipped frame\n",
    "        out.write(frame)\n",
    "        \n",
    "        gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame',gray)\n",
    "        \n",
    "        #IF user press q then quit the window\n",
    "        #waitkey is that wait whenever user give any input\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "# Release everything if job is finished\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.Scaling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('Picture1-1.jpg')\n",
    "\n",
    "res = cv2.resize(img,None,fx=2, fy=2)\n",
    "cv2.imshow(\"befor\",img)\n",
    "cv2.imshow(\"befo\",res)\n",
    "\n",
    "#OR\n",
    "\n",
    "height, width = img.shape[:2]\n",
    "res = cv2.resize(img,(2*width, 2*height))\n",
    "cv2.imshow(\"After\",res)\n",
    "\n",
    "h=cv2.waitKey(0)#when you anykey its store in h,27 is for q\n",
    "if h==ord('q'):\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Colorspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more than 150 color-space conversion methods available in OpenCV. \n",
    "But we will look into only two which are most widely used ones, \n",
    "BGR-Gray and BGR -HSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "# print(flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img=cv2.imread('Picture1-1.jpg',1)#read a image \n",
    "cv2.imshow(\"original\",img)\n",
    "\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"gray\",gray)\n",
    "\n",
    "h=cv2.waitKey(0)#when you anykey its store in h,27 is for q\n",
    "if h==ord('q'):\n",
    "    cv2.destroyAllWindows()\n",
    "elif h== ord('s'):\n",
    "    cv2.imwrite('hcopy.png',img)\n",
    "    cv2.destroyAllWindows()\n",
    "print(\"Image Properties\")\n",
    "print(\"- Number of Pixels: \" + str(img.size))\n",
    "print(\"- Shape/Dimensions: \" + str(img.shape))\n",
    "print(\"- Number of Pixels gray: \" + str(gray.size))\n",
    "print(\"- Shape/Dimensions gray: \" + str(gray.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d5bd03f658c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mahima\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2722\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m         data=None, **kwargs):\n\u001b[1;32m-> 2724\u001b[1;33m     __ret = gca().imshow(\n\u001b[0m\u001b[0;32m   2725\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2726\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mahima\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1438\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mahima\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5523\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mahima\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    698\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[0;32m    699\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m--> 700\u001b[1;33m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0m\u001b[0;32m    701\u001b[0m                             \"float\".format(self._A.dtype))\n\u001b[0;32m    702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('image thres.jpg',0)\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1=cv2.imread('image1.png')\n",
    "img1=cv2.resize(img1,(500,250))\n",
    "\n",
    "# img1=np.zeros((250,500,3),np.uint8)\n",
    "# img1=cv2.rectangle(img1,(200,0),(300,100),(255,255,255),-1)\n",
    "# img2=cv2.imread('Picture1-1.jpg')\n",
    "img2=cv2.imread('image2.png')\n",
    "\n",
    "img2=cv2.resize(img2,(500,250))\n",
    "print(img2.shape)\n",
    "bitwiseand=cv2.bitwise_xor(img2,img1)\n",
    "\n",
    "add_img=cv2.add(img1,img2)\n",
    "cv2.imshow('image1',img1)\n",
    "cv2.imshow('image2',img2)\n",
    "cv2.imshow('image3',bitwiseand)\n",
    "cv2.imshow('add_img',add_img)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
